{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier for CEFR Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, Convolution1D, MaxPooling1D, Dropout, Flatten, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import cPickle as pickle\n",
    "import re\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import bcolz\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = 'data/sentences/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_path = 'data/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cefr_levels = ['a1','a2','b1','b2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort data into train, valid, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%mkdir data/train\n",
    "%mkdir data/valid\n",
    "%mkdir data/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = 'data/train/'\n",
    "valid_path = 'data/valid/'\n",
    "test_path =  'data/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_line(line):\n",
    "    raw = line.strip().decode('unicode_escape').encode('ascii','ignore')\n",
    "    words = re.findall(r\"\\w+|[^\\w\\s]\", raw, re.UNICODE)\n",
    "    return [word.lower() for word in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Make a first pass through the data to create an index of all words used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('.', 15372), ('the', 12689), (',', 12559), ('to', 6580), ('and', 5894), ('of', 5629), ('a', 5283), ('i', 3822), ('in', 3132), ('you', 2981), ('that', 2808), ('he', 2681), ('it', 2551), ('said', 2160), ('is', 2109), ('was', 1937), ('?', 1790), ('be', 1784), (\"'\", 1689), ('as', 1591), ('not', 1579), ('for', 1537), ('but', 1524), ('at', 1504), ('have', 1492), ('if', 1443), ('his', 1415), ('on', 1273), ('with', 1264), ('they', 1238), ('she', 1210), ('do', 1201), ('we', 1180), ('this', 1127), ('what', 1037), ('will', 1023), ('looked', 1017), ('her', 1011), ('!', 1008), ('had', 972), ('are', 962), ('-', 953), ('all', 903), ('its', 792), ('up', 783), ('were', 779), ('by', 747), ('so', 735), ('from', 729), ('an', 723)]\n"
     ]
    }
   ],
   "source": [
    "base_file = '_sentences.txt'\n",
    "idx = defaultdict(int)\n",
    "for l in range(len(cefr_levels)):\n",
    "    with open(data_path + cefr_levels[l] + base_file,'r') as f:\n",
    "        for line in f:\n",
    "            words = process_line(line)\n",
    "            for word in words:\n",
    "                idx[word] += 1\n",
    "\n",
    "final_words = sorted(idx.items(), key=lambda x: x[1])\n",
    "final_words.reverse()\n",
    "print(final_words[:50])\n",
    "idx2word = [ i[0] for i in final_words ]\n",
    "word2idx = dict((v,k) for k,v in enumerate(idx2word))\n",
    "\n",
    "pickle.dump(idx2word,  open(data_path + \"idx2word.p\", 'wb'))\n",
    "pickle.dump(word2idx,  open(data_path + \"word2idx.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_share = 0.65\n",
    "valid_share = 0.2\n",
    "test_share = 0.15\n",
    "assert train_share + valid_share + test_share == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a1', 2487)\n",
      "('a2', 5110)\n",
      "('b1', 6371)\n",
      "('b2', 4806)\n",
      "18774\n"
     ]
    }
   ],
   "source": [
    "base_file = '_sentences.txt'\n",
    "total_count = 0\n",
    "train = np.empty((1,2),dtype='object')\n",
    "valid = np.empty((1,2),dtype='object')\n",
    "test  = np.empty((1,2),dtype='object')\n",
    "for l in range(len(cefr_levels)):\n",
    "    level = []\n",
    "    with open(data_path + cefr_levels[l] + base_file,'r') as f:\n",
    "        for line in f:\n",
    "            words = process_line(line)\n",
    "            level.append((words,l))\n",
    "    count = len(level)\n",
    "    total_count += count\n",
    "    print(cefr_levels[l],count)\n",
    "    train_idx = int(train_share * count)\n",
    "    valid_idx = int(valid_share * count) + train_idx\n",
    "    shuf = np.random.permutation(level)\n",
    "    train = np.concatenate((train, shuf[:train_idx]))\n",
    "    valid = np.concatenate((valid, shuf[train_idx:valid_idx]))\n",
    "    test  = np.concatenate((test,  shuf[valid_idx:]))\n",
    "\n",
    "pickle.dump(np.random.permutation(train[1:]), open(train_path + \"sentences.p\", 'wb'))  \n",
    "pickle.dump(np.random.permutation(valid[1:]), open(valid_path + \"sentences.p\", 'wb'))\n",
    "pickle.dump(np.random.permutation(test[1:]),  open(test_path + \"sentences.p\", 'wb'))\n",
    "\n",
    "print(total_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx2word = pickle.load(open(data_path + \"idx2word.p\", 'rb'))\n",
    "word2idx = pickle.load(open(data_path + \"word2idx.p\", 'rb'))\n",
    "\n",
    "train_file = pickle.load(open(train_path + 'sentences.p','rb'))\n",
    "valid_file = pickle.load(open(valid_path + 'sentences.p','rb'))\n",
    "test_file  = pickle.load(open(test_path + 'sentences.p','rb'))\n",
    "\n",
    "train, train_labels = zip(*train_file)\n",
    "valid, valid_labels = zip(*valid_file)\n",
    "test, test_labels   = zip(*test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert len(train) + len(valid) + len(test) == total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limit vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "train = [np.array([word2idx[i] if word2idx[i] <= vocab_size-1 else vocab_size-1 for i in line ]) for line in train]\n",
    "valid = [np.array([word2idx[i] if word2idx[i] <= vocab_size-1 else vocab_size-1 for i in line ]) for line in valid]\n",
    "test  = [np.array([word2idx[i] if word2idx[i] <= vocab_size-1 else vocab_size-1 for i in line ]) for line in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation (experimental and apparently useless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subs = {\n",
    "    'dog':'cat',\n",
    "    'cat':'dog',\n",
    "    'he':'she',\n",
    "    'she':'he',\n",
    "    'him':'her',\n",
    "    'her':'him',\n",
    "    'this':'that',\n",
    "    'that':'this',\n",
    "    'these':'those',\n",
    "    'those':'these',\n",
    "    'like':'love',\n",
    "    'likes':'loves',\n",
    "    'is':'was',\n",
    "    'was':'is',\n",
    "    'have':'had',\n",
    "    'had':'have'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub2idx = {word2idx[key]: word2idx[value] for key,value in subs.iteritems()}\n",
    "dogidx = word2idx['dog']\n",
    "assert sub2idx[dogidx] == word2idx['cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment_line(line):\n",
    "    augmented = []\n",
    "    for word in line:\n",
    "        if word in sub2idx:\n",
    "            augmented.append(sub2idx[word])\n",
    "        else:\n",
    "            augmented.append(word)\n",
    "    return augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_aug = []\n",
    "train_labels_aug = []\n",
    "for i in range(len(train)):\n",
    "    line = train[i]\n",
    "    augmented = augment_line(line)\n",
    "    if not np.array_equal(augmented,line):\n",
    "        train_aug.append(augmented)\n",
    "        train_labels_aug.append(train_labels[i])\n",
    "train_aug = np.concatenate((train, train_aug))\n",
    "train_labels_aug = np.concatenate((train_labels,train_labels_aug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18690\n"
     ]
    }
   ],
   "source": [
    "print(len(train_aug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in this connection it is worth wrinkled the wrinkled of the great theoretical physicist j .'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(idx2word[i] for i in train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use one-hot encoding on the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_labels)\n",
    "valid_labels = to_categorical(valid_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "#train_labels_aug = to_categorical(train_labels_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  1.])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure all sets have the same ratios of each of the 4 CEFR labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_ratios(labels):\n",
    "    length = float(len(labels))\n",
    "    a1 = sum(labels[i][0] for i in range(len(labels)))\n",
    "    a2 = sum(labels[i][1] for i in range(len(labels)))\n",
    "    b1 = sum(labels[i][2] for i in range(len(labels)))\n",
    "    b2 = sum(labels[i][3] for i in range(len(labels)))\n",
    "    return (a1 / length, a2 / length, b1 / length, b2 / length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.13267115998581058, 0.27208229868747785, 0.33912735012415751, 0.25611919120255411)\n"
     ]
    }
   ],
   "source": [
    "ratios = check_ratios(test_labels)\n",
    "print ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_len = [np.max([len(i) for i in j] for j in [train,valid,test])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq_len = 150\n",
    "train = pad_sequences(train, maxlen=seq_len, value=0)\n",
    "train_aug = pad_sequences(train_aug, maxlen=seq_len, value=0)\n",
    "valid = pad_sequences(valid, maxlen=seq_len, value=0)\n",
    "test = pad_sequences(test, maxlen=seq_len, value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build basic dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size,32,input_length=seq_len))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(4,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12201 samples, validate on 3754 samples\n",
      "Epoch 1/5\n",
      "12201/12201 [==============================] - 1s - loss: 0.4932 - acc: 0.7611 - val_loss: 0.4030 - val_acc: 0.8109\n",
      "Epoch 2/5\n",
      "12201/12201 [==============================] - 1s - loss: 0.3471 - acc: 0.8461 - val_loss: 0.2317 - val_acc: 0.9031\n",
      "Epoch 3/5\n",
      "12201/12201 [==============================] - 1s - loss: 0.2005 - acc: 0.9206 - val_loss: 0.1675 - val_acc: 0.9349\n",
      "Epoch 4/5\n",
      "12201/12201 [==============================] - 1s - loss: 0.1353 - acc: 0.9517 - val_loss: 0.1569 - val_acc: 0.9380\n",
      "Epoch 5/5\n",
      "12201/12201 [==============================] - 1s - loss: 0.1059 - acc: 0.9638 - val_loss: 0.1591 - val_acc: 0.9381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe6b5b15390>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, train_labels, validation_data=(valid,valid_labels), nb_epoch=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12201 samples, validate on 3754 samples\n",
      "Epoch 1/5\n",
      "12201/12201 [==============================] - 1s - loss: 0.0872 - acc: 0.9708 - val_loss: 0.1749 - val_acc: 0.9375\n",
      "Epoch 2/5\n",
      "12201/12201 [==============================] - 1s - loss: 0.0757 - acc: 0.9750 - val_loss: 0.1787 - val_acc: 0.9400\n",
      "Epoch 3/5\n",
      "12201/12201 [==============================] - 1s - loss: 0.0622 - acc: 0.9798 - val_loss: 0.1912 - val_acc: 0.9387\n",
      "Epoch 4/5\n",
      "12201/12201 [==============================] - 1s - loss: 0.0541 - acc: 0.9819 - val_loss: 0.2007 - val_acc: 0.9363\n",
      "Epoch 5/5\n",
      "12201/12201 [==============================] - 1s - loss: 0.0480 - acc: 0.9852 - val_loss: 0.2138 - val_acc: 0.9342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe6c0f91250>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 0.0000001\n",
    "model.fit(train, train_labels, validation_data=(valid,valid_labels), nb_epoch=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN with single convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnn = Sequential()\n",
    "cnn.add(Embedding(vocab_size,64,input_length=seq_len,dropout=0.2))\n",
    "cnn.add(Convolution1D(64,5,border_mode='same', activation='relu'))\n",
    "cnn.add(Dropout(0.2))\n",
    "cnn.add(MaxPooling1D())\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(100,activation='relu'))\n",
    "cnn.add(Dropout(0.8))\n",
    "cnn.add(Dense(4,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12201 samples, validate on 3754 samples\n",
      "Epoch 1/6\n",
      "12201/12201 [==============================] - 4s - loss: 0.4546 - acc: 0.7830 - val_loss: 0.3145 - val_acc: 0.8632\n",
      "Epoch 2/6\n",
      "12201/12201 [==============================] - 4s - loss: 0.2977 - acc: 0.8725 - val_loss: 0.2135 - val_acc: 0.9088\n",
      "Epoch 3/6\n",
      "12201/12201 [==============================] - 4s - loss: 0.2377 - acc: 0.9017 - val_loss: 0.1852 - val_acc: 0.9202\n",
      "Epoch 4/6\n",
      "12201/12201 [==============================] - 4s - loss: 0.2033 - acc: 0.9188 - val_loss: 0.1684 - val_acc: 0.9343\n",
      "Epoch 5/6\n",
      "12201/12201 [==============================] - 4s - loss: 0.1801 - acc: 0.9314 - val_loss: 0.1588 - val_acc: 0.9380\n",
      "Epoch 6/6\n",
      "12201/12201 [==============================] - 4s - loss: 0.1553 - acc: 0.9400 - val_loss: 0.1552 - val_acc: 0.9406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe6be050890>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(train, train_labels, validation_data=(valid,valid_labels), nb_epoch=6, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn.optimizer.lr = 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnn.save_weights(model_path + 'cnn1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn.load_weights(model_path + 'cnn1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_array(arr):\n",
    "    return bcolz.open(arr)[:]\n",
    "\n",
    "def load_vectors(loc):\n",
    "    return (load_array(loc+'.dat'),\n",
    "        pickle.load(open(loc+'_words.pkl','rb')),\n",
    "        pickle.load(open(loc+'_idx.pkl','rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vecs, words, wordidx = load_vectors('data/glove/results/6B.300d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_embedding():\n",
    "    num_factors = vecs.shape[1]\n",
    "    emb = np.zeros((vocab_size,num_factors))\n",
    "    \n",
    "    for i in range(1,len(emb)):\n",
    "        word = idx2word[i]\n",
    "        if word and word in wordidx:\n",
    "            emb[i] = vecs[wordidx[word]]\n",
    "        elif word and re.match(r\"^[a-zA-Z0-9\\-]*$\", word):\n",
    "            emb[i] = np.random.normal(scale=0.6,size=(num_factors,))\n",
    "        else:\n",
    "            emb[i] = np.random.normal(scale=0.6,size=(num_factors,))\n",
    "    \n",
    "    emb[-1] = np.random.normal(scale=0.6,size=(num_factors,))\n",
    "    emb/= 3\n",
    "    return emb\n",
    "\n",
    "emb = create_embedding()        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 300)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glove = Sequential()\n",
    "glove.add(Embedding(vocab_size,emb.shape[1],input_length=seq_len,dropout=0.2, weights=[emb], trainable=True))\n",
    "glove.add(Convolution1D(64,3,border_mode='same', activation='relu'))\n",
    "glove.add(Dropout(0.2))\n",
    "glove.add(BatchNormalization())\n",
    "glove.add(MaxPooling1D())\n",
    "\n",
    "glove.add(Flatten())\n",
    "glove.add(Dense(100,activation='relu'))\n",
    "glove.add(Dropout(0.75))\n",
    "glove.add(BatchNormalization())\n",
    "glove.add(Dense(4,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12201 samples, validate on 3754 samples\n",
      "Epoch 1/10\n",
      "12201/12201 [==============================] - 8s - loss: 0.4686 - acc: 0.7832 - val_loss: 0.5123 - val_acc: 0.7519\n",
      "Epoch 2/10\n",
      "12201/12201 [==============================] - 8s - loss: 0.3425 - acc: 0.8469 - val_loss: 0.4258 - val_acc: 0.7939\n",
      "Epoch 3/10\n",
      "12201/12201 [==============================] - 8s - loss: 0.2723 - acc: 0.8854 - val_loss: 0.2896 - val_acc: 0.8875\n",
      "Epoch 4/10\n",
      "12201/12201 [==============================] - 8s - loss: 0.2216 - acc: 0.9114 - val_loss: 0.2093 - val_acc: 0.9216\n",
      "Epoch 5/10\n",
      "12201/12201 [==============================] - 8s - loss: 0.1969 - acc: 0.9237 - val_loss: 0.1920 - val_acc: 0.9245\n",
      "Epoch 6/10\n",
      "12201/12201 [==============================] - 8s - loss: 0.1788 - acc: 0.9315 - val_loss: 0.1628 - val_acc: 0.9350\n",
      "Epoch 7/10\n",
      "12201/12201 [==============================] - 8s - loss: 0.1700 - acc: 0.9354 - val_loss: 0.1750 - val_acc: 0.9276\n",
      "Epoch 8/10\n",
      "12201/12201 [==============================] - 8s - loss: 0.1576 - acc: 0.9412 - val_loss: 0.1580 - val_acc: 0.9347\n",
      "Epoch 9/10\n",
      "12201/12201 [==============================] - 8s - loss: 0.1439 - acc: 0.9468 - val_loss: 0.1726 - val_acc: 0.9306\n",
      "Epoch 10/10\n",
      "12201/12201 [==============================] - 8s - loss: 0.1403 - acc: 0.9489 - val_loss: 0.1613 - val_acc: 0.9361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe6ad417750>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.fit(train, train_labels, validation_data=(valid,valid_labels), nb_epoch=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glove.optimizer.lr = 0.00000001\n",
    "glove.layers[0].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12201 samples, validate on 3754 samples\n",
      "Epoch 1/6\n",
      "12201/12201 [==============================] - 8s - loss: 0.0907 - acc: 0.9674 - val_loss: 0.1688 - val_acc: 0.9363\n",
      "Epoch 2/6\n",
      "12201/12201 [==============================] - 8s - loss: 0.0885 - acc: 0.9693 - val_loss: 0.1898 - val_acc: 0.9331\n",
      "Epoch 3/6\n",
      "12201/12201 [==============================] - 8s - loss: 0.0855 - acc: 0.9698 - val_loss: 0.1738 - val_acc: 0.9359\n",
      "Epoch 4/6\n",
      "12201/12201 [==============================] - 8s - loss: 0.0841 - acc: 0.9702 - val_loss: 0.1871 - val_acc: 0.9332\n",
      "Epoch 5/6\n",
      "12201/12201 [==============================] - 8s - loss: 0.0802 - acc: 0.9714 - val_loss: 0.1885 - val_acc: 0.9337\n",
      "Epoch 6/6\n",
      "12201/12201 [==============================] - 8s - loss: 0.0757 - acc: 0.9729 - val_loss: 0.1769 - val_acc: 0.9343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe69f052d50>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.fit(train, train_labels, validation_data=(valid,valid_labels), nb_epoch=6, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove.save_weights(model_path + 'glove1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "glove.load_weights(model_path + 'glove1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check results of predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2819, 150)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = glove.predict(test,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_labels = ([np.argmax(p) for p in preds])\n",
    "expected_labels = ([np.argmax(p) for p in test_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(expected_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    (This function is copied from the scikit docs.)\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print(cm)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[237  98  33   6]\n",
      " [  6 693  51  17]\n",
      " [  5  54 852  45]\n",
      " [  0  16  56 650]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc4AAAGbCAYAAABNpXD0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmZkV4f8BsjsB007VRIAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe6ac5f9190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cm, cefr_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387\n",
      "Accuracy:0.86271727563\n"
     ]
    }
   ],
   "source": [
    "# Cases where the model guessed incorrectly\n",
    "errors = 0\n",
    "for i in range(len(expected_labels)):\n",
    "    if expected_labels[i] != predicted_labels[i]:\n",
    "        errors += 1\n",
    "        #print expected_labels[i]\n",
    "        #print predicted_labels[i]\n",
    "        #print ' '.join([idx2word[w] for w in test[i]])\n",
    "print(errors)\n",
    "print('Accuracy: ' + str(1.0 - (errors / len(test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Try using pseudolabeled IMDB data\n",
    "#### (Seems ineffective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "idx = imdb.get_word_index()\n",
    "idx_arr = sorted(idx, key=idx.get)\n",
    "imdb_idx2word = {v: k for k, v in idx.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = get_file('imdb_full.pkl',\n",
    "                origin='https://s3.amazonaws.com/text-datasets/imdb_full.pkl',\n",
    "                md5_hash='d091312047c43cf9e4e38fef92437263')\n",
    "f = open(path, 'rb')\n",
    "(imdb_train,imdb_labels), (imdb_test, imdb_test_labels) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"bromwell high is a cartoon comedy it ran at the same time as some other programs about school life such as teachers my 35 years in the teaching profession lead me to believe that bromwell high's satire is much closer to reality than is teachers the scramble to survive financially the insightful students who can see right through their pathetic teachers' pomp the pettiness of the whole situation all remind me of the schools i knew and their students when i saw the episode in which a student repeatedly tried to burn down the school i immediately recalled at high a classic line inspector i'm here to sack one of your teachers student welcome to bromwell high i expect that many adults of my age think that bromwell high is far fetched what a pity that it isn't\""
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review1 = [imdb_idx2word[x] for x in imdb_train[0]]\n",
    "' '.join(review1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "imdb_train = [np.array([i if i<=vocab_size-1 else vocab_size-1 for i in s]) for s in imdb_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrinkled\n"
     ]
    }
   ],
   "source": [
    "print(idx2word[4999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 150)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 150\n",
    "\n",
    "imdb_train = pad_sequences(imdb_train, maxlen=seq_len, value=0)\n",
    "imdb_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0 4999  309    6\n",
      "    3 1069  209    9 2175   30    1  169   55   14   46   82 4999   41  393\n",
      "  110  138   14 4999   58 4477  150    8    1 4999 4999  482   69    5  261\n",
      "   12 4999 4999 2003    6   73 2436    5  632   71    6 4999    1 4999    5\n",
      " 2004 4999    1 4999 1534   34   67   64  205  140   65 1232 4999 4999    1\n",
      " 4999    4    1  223  901   29 3024   69    4    1 4999   10  694    2   65\n",
      " 1534   51   10  216    1  387    8   60    3 1472 3724  802    5 3521  177\n",
      "    1  393   10 1238 4999   30  309    3  353  344 2989  143  130    5 4999\n",
      "   28    4  126 4999 1472 2375    5 4999  309   10  532   12  108 1470    4\n",
      "   58  556  101   12 4999  309    6  227 4187   48    3 2237   12    9  215]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'. . . . . . . . . . . . wrinkled side a to 2 moment you extraordinary she the after think is by ve wrinkled - nervously way why is wrinkled see stroke thing in the wrinkled wrinkled early could of small it wrinkled wrinkled wagon a theory bob of met which a wrinkled the wrinkled of sighed wrinkled the wrinkled ceiling what then about oh much me le wrinkled wrinkled the wrinkled and the ever hardly they dimbleby could and the wrinkled that car , me ceiling or that few the important in their to description collect none of improvement world the nervously that asriel wrinkled she side to clearly example raccoons things understand of wrinkled with and right wrinkled description theresa of wrinkled side that saying it too properly and see nature henry it wrinkled side a also elsewhere from to picking it you ri'"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(imdb_train[0])\n",
    "' '.join([idx2word[i] for i in imdb_train[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_size = train.shape[0]\n",
    "imdb_sample = np.random.permutation(imdb_train)[:int(train_size/3)]\n",
    "imdb_sample_preds = glove.predict(imdb_sample, batch_size=64)\n",
    "imdb_sample_labels = ([np.argmax(p) for p in imdb_sample_preds])\n",
    "imdb_sample_labels = to_categorical(imdb_sample_labels)\n",
    "train_with_pseudolabeled_data = np.concatenate((train, imdb_sample))\n",
    "labels_with_pseudolabeled_data = np.concatenate((train_labels, imdb_sample_labels))\n",
    "assert len(train_with_pseudolabeled_data) == len(labels_with_pseudolabeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16268 samples, validate on 3754 samples\n",
      "Epoch 1/6\n",
      "16268/16268 [==============================] - 10s - loss: 0.1430 - acc: 0.9482 - val_loss: 0.1767 - val_acc: 0.9327\n",
      "Epoch 2/6\n",
      "16268/16268 [==============================] - 10s - loss: 0.1137 - acc: 0.9578 - val_loss: 0.1748 - val_acc: 0.9333\n",
      "Epoch 3/6\n",
      "16268/16268 [==============================] - 10s - loss: 0.1159 - acc: 0.9572 - val_loss: 0.2063 - val_acc: 0.9200\n",
      "Epoch 4/6\n",
      "16268/16268 [==============================] - 10s - loss: 0.1223 - acc: 0.9533 - val_loss: 0.1645 - val_acc: 0.9367\n",
      "Epoch 5/6\n",
      "16268/16268 [==============================] - 10s - loss: 0.1060 - acc: 0.9618 - val_loss: 0.1759 - val_acc: 0.9359\n",
      "Epoch 6/6\n",
      "16268/16268 [==============================] - 10s - loss: 0.0972 - acc: 0.9648 - val_loss: 0.1809 - val_acc: 0.9366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe6b6bd2650>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.fit(train_with_pseudolabeled_data, labels_with_pseudolabeled_data, validation_data=(valid,valid_labels), nb_epoch=6, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16268 samples, validate on 3754 samples\n",
      "Epoch 1/6\n",
      "16268/16268 [==============================] - 15s - loss: 0.1532 - acc: 0.9421 - val_loss: 0.1603 - val_acc: 0.9347\n",
      "Epoch 2/6\n",
      "16268/16268 [==============================] - 15s - loss: 0.1522 - acc: 0.9407 - val_loss: 0.1682 - val_acc: 0.9292\n",
      "Epoch 3/6\n",
      "16268/16268 [==============================] - 15s - loss: 0.1474 - acc: 0.9428 - val_loss: 0.1695 - val_acc: 0.9301\n",
      "Epoch 4/6\n",
      "16268/16268 [==============================] - 15s - loss: 0.1426 - acc: 0.9442 - val_loss: 0.1795 - val_acc: 0.9285\n",
      "Epoch 5/6\n",
      "16268/16268 [==============================] - 15s - loss: 0.1371 - acc: 0.9466 - val_loss: 0.1665 - val_acc: 0.9340\n",
      "Epoch 6/6\n",
      "16268/16268 [==============================] - 15s - loss: 0.1360 - acc: 0.9470 - val_loss: 0.1786 - val_acc: 0.9259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6960f12950>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.optimizer.lr = 0.000001\n",
    "glove.layers[0].trainable = True\n",
    "glove.fit(train_with_pseudolabeled_data, labels_with_pseudolabeled_data, validation_data=(valid,valid_labels), nb_epoch=6, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
